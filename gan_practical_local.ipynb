{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1rhzu_KRVfD"
   },
   "source": [
    "# Data synthesis using generative adversarial networks (GANs)\n",
    "\n",
    "In this practical session we will build and train generative adversarial networks that are able to generate images.\n",
    "\n",
    "This is a Google Colab notebook, which is mostly the same as a Jupyter notebook. This means that you can run the code in a cell by selecting the cell and pressing Shift+Enter. In contrast to last week, we will run everything in the cloud, so you don't need a fancy computer or an expensive GPU for this exercise. We are going to use GPUs that Google Cloud provides for free. To do this, go to Edit --> Notebook settings and select GPU as Hardware accelerator. Then, in the top right of this screen select 'CONNECT' --> 'Connect to hosted runtime'\n",
    "\n",
    "Like before, we are going to import some of the packages that we will need in this exercise (by running the cell below)\n",
    "\n",
    "The documentation for key packages can be found online: <br>\n",
    "For numpy: https://docs.scipy.org/doc/numpy-dev/user/quickstart.html <br>\n",
    "For matplotlib: http://matplotlib.org/api/pyplot_api.html <br>\n",
    "For Keras: https://keras.io/ <br>\n",
    "For random: https://docs.python.org/2/library/random.html <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV9fYTQRRQ6J"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "from matplotlib import pylab\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "import time\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9hTkVp1ESQW"
   },
   "source": [
    "## Small steps\n",
    "Before moving on to generating images, we will start with a simple 1D problem. We will assume that there is a data set of real samples that are drawn from a normal distribution with a particular mean value (the black dotted line below). These samples are in the sample domain *x*. \n",
    "\n",
    "The generator network does not know anything about the distribution of the real samples in the sample domain *x*, but will try to come up with a transformation that maps random noise from a distribution *z* to samples that seem to come from the real sample distribution (the green line below). This is very similar to what we have looked at in the lecture.\n",
    "\n",
    "<img src=\"https://cs.stanford.edu/people/karpathy/gan/gan.png\">\n",
    "\n",
    "For this, we will define two neural networks that play a game:\n",
    "*   The discriminator will learn to distinguish real and fake samples in *z*\n",
    "*   The generator will generate fake samples in *z* that the discriminator cannot discriminate\n",
    "\n",
    "First, we determine the mean value of the normal distribution from which **real** samples will be drawn in the sample domain *x*. In addition, we define the dimensionality of the normal distribution *z* from which noise samples to the generator will be drawn, i.e. the latent space. This will be 1 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rsg4CLVHgMeJ"
   },
   "outputs": [],
   "source": [
    "real_mean = 8\n",
    "latent_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eLRuaRXgSKn"
   },
   "source": [
    "Next, we define our discriminator and generator. These are both very simple networks.\n",
    "\n",
    "**Question** How many layers does each of these networks have? \n",
    "\n",
    "**Question** Can you find out how many trainable parameters the networks have?\n",
    "\n",
    "**Question** What are the activation functions of both networks? Why are they like this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ACf058DjgZ9_"
   },
   "outputs": [],
   "source": [
    "# For easier reading\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# The discriminator will directly classify the input value\n",
    "def get_discriminator_1D():\n",
    "  discriminator = keras.models.Sequential()\n",
    "  discriminator.add(Dense(32, input_dim=1))\n",
    "  discriminator.add(LeakyReLU())\n",
    "  discriminator.add(Dense(1, activation='sigmoid'))\n",
    "  return discriminator\n",
    "\n",
    "# The generator will transform a single input value\n",
    "def get_generator_1D():\n",
    "  generator = keras.models.Sequential()\n",
    "  generator.add(Dense(32, input_dim=1))\n",
    "  generator.add(LeakyReLU())\n",
    "  generator.add(Dense(1))\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QYrW32ehE3_"
   },
   "source": [
    "Now, we will define the training functions for both networks. Consider what is actually happening in a GAN and how the inputs and outputs are connected. There are three variables when training this GAN\n",
    "\n",
    "*   **z**: the noise that will be input to the generator\n",
    "*   **G_z**: the output of the generator, i.e. the samples that should approximate the real samples\n",
    "*   **D_G_z**: the discriminator's decision based on the fake sample\n",
    "\n",
    "The overall objective function of our system is as follows\n",
    "\n",
    "$V^{(D)}(D,G)=\\underset{x\\sim p_{data}}{\\mathbb{E}} [\\log{D(x)}]+\\underset{z\\sim p_z}{\\mathbb{E}} [\\log{(1-D(G(z)))}]$\n",
    "\n",
    "The generator $G$ is trying to minimize this loss, and the discriminator $D$ tries to maximize this. In other words, the discriminator wants to minimize the binary cross-entropy s.t. it predicts 1 for real samples and 0 for fake samples. At the same time, the generator tries to get the discriminator to predict 1 for fake samples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "H30WDcfXF7tY"
   },
   "outputs": [],
   "source": [
    "# Get networks\n",
    "discriminator = get_discriminator_1D()\n",
    "generator = get_generator_1D()\n",
    "\n",
    "# Configure both models for training\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "# To configure the full model, we will set the 'trainable' parameter of the discriminator to False, as we don't want to optimize the discriminator when optimizing the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The input variable (noise) for the generator\n",
    "z = keras.layers.Input(shape=(latent_dim,))\n",
    "\n",
    "# What comes out of the generator\n",
    "G_z = generator(z)\n",
    "\n",
    "# What comes out of the discriminator when classifying the 'fake' samples\n",
    "D_G_z = discriminator(G_z)\n",
    "\n",
    "# The full GAN model\n",
    "gan = keras.models.Model(inputs=z, outputs=D_G_z)\n",
    "\n",
    "# The loss function for the GAN: this gets lower if the fake samples are classified as real\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MlpUJ_716Tk"
   },
   "source": [
    "The code below runs the training loop. This could take a while. The code will periodically show a plot of the current situation.\n",
    "\n",
    "**Question** Why do we set discriminator.trainable to either True or False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynLndgse0r9V"
   },
   "outputs": [],
   "source": [
    "# We will store the losses here\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "# Training loop\n",
    "n_samples = 100\n",
    "epochs = 10000\n",
    "\n",
    "for e in range(epochs):\n",
    "  # Get a random set of input noise\n",
    "  noise = np.random.normal(0, 1, size=[n_samples, latent_dim])\n",
    "\n",
    "  # Also get a sample from the 'real' distribution\n",
    "  real = np.random.normal(real_mean, 1, size=[n_samples, latent_dim])\n",
    "\n",
    "  # Generate some fake samples using the generator\n",
    "  fake = generator.predict(noise)\n",
    "\n",
    "  # Concatenate the fake and real images\n",
    "  X = np.concatenate([real, fake])\n",
    "\n",
    "  # Labels for generated and real data\n",
    "  Y_dis = np.zeros(2*n_samples)\n",
    "  \n",
    "  # Set labels for real samples to 1\n",
    "  Y_dis[:n_samples] = 1\n",
    "\n",
    "  # Train discriminator with this batch of samples\n",
    "  discriminator.trainable = True\n",
    "  d_loss = discriminator.train_on_batch(X, Y_dis)\n",
    "  d_losses.append(d_loss)\n",
    "  \n",
    "  # Train generator with a new batch of generated samples\n",
    "  # Freeze the discriminator part\n",
    "  discriminator.trainable = False \n",
    "  noise = np.random.normal(0, 1, size=[n_samples, latent_dim])\n",
    "  # From the generator's perspective, the discriminator should predict\n",
    "  # ones for all samples\n",
    "  Y_gen = np.ones(n_samples)\n",
    "  g_loss = gan.train_on_batch(noise, Y_gen)\n",
    "  g_losses.append(g_loss)\n",
    "  \n",
    "  if e % 100 == 0:\n",
    "    noise = np.random.normal(0, 1, size=[n_samples, latent_dim])\n",
    "    fake = generator.predict(noise)        \n",
    "    real = np.random.normal(real_mean, 1, size=[n_samples, latent_dim])\n",
    "    pred = discriminator.predict(np.arange(-20, 20, 0.5).reshape((80, 1)))\n",
    "    plt.clf()\n",
    "    plt.hist((np.squeeze(fake), np.squeeze(real)), density=True, stacked=True)\n",
    "    plt.scatter(np.arange(-20, 20, 0.5), pred, c='r')     \n",
    "    plt.xlim(-20, 20)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Iteration {}'.format(e))\n",
    "    plt.legend(['Discriminator', 'Fake', 'Real'])\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbNFeFkSbXoN"
   },
   "source": [
    "If all is well, the fake and real distributions should nicely overlap after training. The discriminator has essentially pushed the fake samples towards the real distribution and the generator is now able to transform the noise distribution into a distribution of 'real' samples!\n",
    "\n",
    "**Question** Can you explain what happened to the red line during training? Why does it look like it does after training?\n",
    "\n",
    "**Question** Try training the GAN with different input noise distributions, e.g. uniform.\n",
    "\n",
    "**Question** See if you can find a distribution for which the generator fails to generate samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuZBMvf4NWvD"
   },
   "source": [
    "During training, we have stored the loss values for the discriminator and the generator. We can now plot these. Remember that for the digit classification task, we were looking for a set of parameters leading to a low loss function. \n",
    "\n",
    "**Question** The loss curves that you get look different. Can you explain why they're not nicely dropping to zero? Can you explain the loss in the discriminator based on the objective function of the discriminator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61bpDVDJNf12"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(d_losses)\n",
    "plt.title('Discriminator loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(g_losses)\n",
    "plt.title('Generator loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dreog2u1b-iI"
   },
   "source": [
    "Although it is definitely nice that we can train two networks together to learn the distribution of a real data distribution, generating samples from a normal distribution is in itself not really interesting. Luckily, we can use the same principles to generate images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hq5i_sySZL1"
   },
   "source": [
    "# MNIST synthesis\n",
    "We are again going to use the MNIST data. Refer to point 2) of last week's exercise to get this data (if you have lost it). Data preparation is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cYMTWk3-Sa6I"
   },
   "outputs": [],
   "source": [
    "def loadMNIST(path):\n",
    "    f = gzip.open(path, 'rb')\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    \n",
    "    train_set_labels = train_set[1]\n",
    "    train_set_images = np.resize(train_set[0],(len(train_set_labels),28,28,1))\n",
    "   \n",
    "    valid_set_labels = valid_set[1]\n",
    "    valid_set_images = np.resize(valid_set[0],(len(valid_set_labels),28,28,1))\n",
    "\n",
    "    test_set_labels = test_set[1]\n",
    "    test_set_images = np.resize(test_set[0],(len(test_set_labels),28,28,1))\n",
    "    \n",
    "    return train_set_labels, train_set_images, valid_set_labels, valid_set_images, test_set_labels, test_set_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-5ls6CemTIX"
   },
   "source": [
    "Plot some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0M65_8qTmOI"
   },
   "outputs": [],
   "source": [
    "MNIST_filename = r'D:\\CapitaSelecta\\mnist.pkl.gz'\n",
    "\n",
    "train_set_labels, train_set_images, valid_set_labels, valid_set_images, test_set_labels, test_set_images = loadMNIST(MNIST_filename)\n",
    "\n",
    "def plotImages(images, dim=(10, 10), figsize=(10, 10), title=''):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "plotImages(train_set_images[np.random.randint(0, train_set_images.shape[0], size=100)].reshape(100, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJnlR4PJSeQB"
   },
   "source": [
    "In last week's exercise you have built a discriminative model that was able to classify an image into one of ten digit categories. In this exercise, we are going to do the inverse. Given a point in a latent space (which in our case will be a multi-dimensional Gaussian distribution), we are going to train the network to generate a realistic digit image for this point. The MNIST data set will be used as a set of real samples. \n",
    "\n",
    "<img src=\"https://skymind.ai/images/wiki/GANs.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blRfoIS4Uo8-"
   },
   "source": [
    "## The discriminator\n",
    "As you can see in the image above, we will need a generator and a discriminator network. Let's define these. Consider the network that you used\n",
    "for digit classification in the previous exercise and see if you can spot some differences between that network and the network below.\n",
    "\n",
    "**Question** Is this a convolutional neural network? Why (not)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qg36jdcyUvPF"
   },
   "outputs": [],
   "source": [
    "def get_discriminator_MLP():\n",
    "  discriminator = keras.models.Sequential()\n",
    "  discriminator.add(Dense(1024, input_dim=784, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "  discriminator.add(LeakyReLU(0.2))\n",
    "  discriminator.add(Dropout(0.3))\n",
    "  discriminator.add(Dense(512))\n",
    "  discriminator.add(LeakyReLU(0.2))\n",
    "  discriminator.add(Dropout(0.3))\n",
    "  discriminator.add(Dense(256))\n",
    "  discriminator.add(LeakyReLU(0.2))\n",
    "  discriminator.add(Dense(1, activation='sigmoid'))\n",
    "  return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KYxSSbBQ28g"
   },
   "source": [
    "You could argue that digits are a bit more complex than samples from a Gaussian distribution, so let's set the latent space dimensionality for noise sampling a bit higher than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MmCVJxAmQ6nE"
   },
   "outputs": [],
   "source": [
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BGSHlx-VmVY"
   },
   "source": [
    "## The generator\n",
    "\n",
    "The generator is different than the discriminator. It should go from a low-dimensional noise vector to an MNIST image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fEjxnxAwVukq"
   },
   "outputs": [],
   "source": [
    "def get_generator_MLP():\n",
    "  generator = keras.models.Sequential()\n",
    "  generator.add(Dense(256, input_dim=latent_dim, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "  generator.add(LeakyReLU(0.2))\n",
    "  generator.add(Dense(512))\n",
    "  generator.add(LeakyReLU(0.2))\n",
    "  generator.add(Dense(1024))\n",
    "  generator.add(LeakyReLU(0.2))\n",
    "  generator.add(Dense(784, activation='tanh'))\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAUU4F7OQxO0"
   },
   "source": [
    "**Question** Consider the activation functions of the output layers of the generator and discriminator networks. How are they different?\n",
    "\n",
    "**Question** Also look at the activation functions of the other layers, can you find out what they do? Look at the Keras documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH_4zv4gnYhg"
   },
   "source": [
    "## The model\n",
    "Now  let's combine the generator and the discriminator. We train both using a binary crossentropy objective. This is very similar to what we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2dR_iHzXXHjb"
   },
   "outputs": [],
   "source": [
    "discriminator = get_discriminator_MLP()\n",
    "generator = get_generator_MLP()\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "discriminator.trainable = False\n",
    "z = keras.layers.Input(shape=(latent_dim,))\n",
    "G_z = generator(z)\n",
    "D_G_z = discriminator(G_z)\n",
    "gan = keras.models.Model(inputs=z, outputs=D_G_z)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRMLacRF_RXo"
   },
   "source": [
    "Some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MPXzOrqYZqmN"
   },
   "outputs": [],
   "source": [
    "def saveModels(epoch):\n",
    "    generator.save('gan_generator_epoch_{}.h5'.format(epoch))\n",
    "    discriminator.save('gan_discriminator_epoch_{}.h5'.format(epoch))\n",
    "    \n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Epoch {}'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSJGSyUOmxCN"
   },
   "source": [
    "Run the code below to train the GAN model. Synthesized images should be shown periodically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYInR4WkXj_g"
   },
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "X_train = (train_set_images.reshape(50000, 784).astype(np.float32) - 0.5)/0.5\n",
    "\n",
    "batch_count = int(X_train.shape[0] / batch_size)\n",
    "for e in range(epochs):\n",
    "  for _ in range(batch_count):\n",
    "\n",
    "    # Get a random set of input noise and images\n",
    "    noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "    image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "\n",
    "    # Generate some fake MNIST images using the generator\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Concatenate the fake and real images\n",
    "    X = np.concatenate([image_batch, generated_images])\n",
    "\n",
    "    # Labels for generated and real data\n",
    "    y_dis = np.zeros(2*batch_size)\n",
    "    # One-sided label smoothing\n",
    "    y_dis[:batch_size] = 0.9\n",
    "\n",
    "    # Train discriminator with this batch of samples\n",
    "    discriminator.trainable = True\n",
    "    d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "    # Train generator with a new batch of generated samples\n",
    "    noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "\n",
    "    # From the generator's perspective, the discriminator should predict\n",
    "    # ones for all samples\n",
    "    y_gen = np.ones(batch_size)\n",
    "\n",
    "    # Freeze the discriminator part\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Train the GAN to predict ones\n",
    "    g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "  # Store loss of most recent batch from this epoch\n",
    "  d_losses.append(d_loss)\n",
    "  g_losses.append(g_loss)\n",
    "\n",
    "  if e % 5 == 0:\n",
    "    noise = np.random.normal(0, 1, size=[100, latent_dim])\n",
    "    plotGeneratedImages(e)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.001)\n",
    "    saveModels(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkAQZ1-uA1SQ"
   },
   "source": [
    "**Question** Inspect the loss curves for this model and explain what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7MFDUeHSgQ-"
   },
   "source": [
    "## A convolutional model\n",
    "Thus far the discriminator and generator were both multilayer perceptrons. Now we're going to add in some convolutional layers to turn them into a deep convolutional GAN (<a href=\"http://arxiv.org/abs/1511.06434\">DCGAN</a>)-like architecture. This means that we have to redefine the generator network and a discriminator network. \n",
    "\n",
    "The discriminator network is (almost) the same network that we used in last week's exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bccrTGP0SiVJ"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "\n",
    "def get_discriminator_CNN():\n",
    "  discriminator = keras.models.Sequential()\n",
    "  discriminator.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(1, 28, 28), kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "  discriminator.add(LeakyReLU(0.2))\n",
    "  discriminator.add(Dropout(0.3))\n",
    "  discriminator.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
    "  discriminator.add(LeakyReLU(0.2))\n",
    "  discriminator.add(Dropout(0.3))\n",
    "  discriminator.add(Flatten())\n",
    "  discriminator.add(Dense(1, activation='sigmoid'))\n",
    "  return discriminator\n",
    "\n",
    "def get_generator_CNN():\n",
    "  generator = keras.models.Sequential()\n",
    "  generator.add(Dense(128*7*7, input_dim=latent_dim, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "  generator.add(LeakyReLU(0.2))\n",
    "  generator.add(Reshape((128, 7, 7)))\n",
    "  generator.add(UpSampling2D(size=(2, 2)))\n",
    "  generator.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
    "  generator.add(LeakyReLU(0.2))\n",
    "  generator.add(UpSampling2D(size=(2, 2)))\n",
    "  generator.add(Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh'))\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JSKkoosKAwrh"
   },
   "source": [
    "Let's build our model like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mu8rmKcoGAPb"
   },
   "outputs": [],
   "source": [
    "discriminator = get_discriminator_CNN()\n",
    "generator = get_generator_CNN()\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "discriminator.trainable = False\n",
    "z = keras.layers.Input(shape=(latent_dim,))\n",
    "x = generator(z)\n",
    "D_G_z = discriminator(x)\n",
    "gan = keras.models.Model(inputs=z, outputs=D_G_z)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ojox3HxJnVDF"
   },
   "source": [
    "Train the model using the code below. Inspect the samples that come out. \n",
    "\n",
    "**Question** What are some differences between these samples and the ones generated by the multilayer perceptron GAN? Can you explain these differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k79EFqsgWz0l"
   },
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "X_train = (train_set_images.reshape(50000, 1, 28, 28).astype(np.float32) - 0.5)/0.5\n",
    "\n",
    "batch_count = int(X_train.shape[0] / batch_size)\n",
    "for e in range(epochs):\n",
    "  for _ in range(batch_count):\n",
    "    # Get a random set of input noise and images\n",
    "    noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "    image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "\n",
    "    # Generate some fake MNIST images using the generator\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Concatenate the fake and real images\n",
    "    X = np.concatenate([image_batch, generated_images])\n",
    "\n",
    "    # Labels for generated and real data\n",
    "    y_dis = np.zeros(2*batch_size)\n",
    "    # Set reference to 1 for real samples\n",
    "    y_dis[:batch_size] = 1\n",
    "\n",
    "    # Train discriminator with this batch of samples\n",
    "    discriminator.trainable = True\n",
    "    d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "    # Train generator with a new batch of generated samples\n",
    "    noise = np.random.normal(0, 1, size=[batch_size, latent_dim])\n",
    "\n",
    "    # From the generator's perspective, the discriminator should predict\n",
    "    # ones for all samples\n",
    "    y_gen = np.ones(batch_size)\n",
    "\n",
    "    # Freeze the discriminator part\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Train the GAN to predict ones\n",
    "    g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "    # Store loss of most recent batch from this epoch\n",
    "  d_losses.append(d_loss)\n",
    "  g_losses.append(g_loss)\n",
    "\n",
    "  if e % 5 == 0:\n",
    "    noise = np.random.normal(0, 1, size=[100, latent_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(100, 28, 28)          \n",
    "    plotImages(generatedImages, title='Epoch {}'.format(e))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.001)    \n",
    "    saveModels(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmtZkf5AnW6y"
   },
   "source": [
    "## Interpolation in the latent space\n",
    "We're going to explore the latent space a bit more. We pick two points in the latent space and make a linear interpolation between these two. Then we generate images from each of the interpolated latent points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NlTG4FBkNpC"
   },
   "outputs": [],
   "source": [
    "noise_a = np.random.normal(0, 1, size=[1, latent_dim])\n",
    "noise_b = np.random.normal(0, 1, size=[1, latent_dim])\n",
    "\n",
    "noise = np.zeros((10, latent_dim), dtype='float32')\n",
    "for ni in range(10):\n",
    "  noise[ni, :] = float(ni)/10. * noise_a + (1 - float(ni)/10.) * noise_b\n",
    "generatedImages = generator.predict(noise)\n",
    "generatedImages = generatedImages.reshape(10, 28, 28)          \n",
    "plotImages(generatedImages, dim=(1, 10), figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxkznblanlBO"
   },
   "source": [
    "**Question** Explain what you see in this plot.\n",
    "\n",
    "**Question** What happens when you extrapolate out of the latent space distribution? Consider how the noise vectors are drawn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEjdfhRZsUGR"
   },
   "source": [
    "# Histopathology image synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhUnPg2sYitQ"
   },
   "source": [
    "Now we're going to synthesize some actual images. We're going to use the PatchCamelyon data set ([more info here](https://github.com/basveeling/pcam)) which consists of small images that can be used for classification benchmarks. Today, we're not going to classify images, but we're going to synthesize them. You can download a data set of smaller (28 x 28 pixels) versions of these images from \n",
    "[this link](https://filesender.surf.nl/?s=download&token=4601bd2c-3de6-4274-b82b-eefc7ae0297d). Upload the data set in the dialog below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lE8OlCi-ZKFf"
   },
   "source": [
    "Now load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NfJIE29rFYUA"
   },
   "outputs": [],
   "source": [
    "def loadPatchCamelyon(path):    \n",
    "    f = gzip.open(path, 'rb')\n",
    "    train_set = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WP1Eho1U1oMX"
   },
   "outputs": [],
   "source": [
    "train_set_images = loadPatchCamelyon(PATCHCAMELYONFILENAME)\n",
    "\n",
    "def plotImagesPatchCamelyon(images, dim=(10, 10), figsize=(10, 10), title=''):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plotImagesPatchCamelyon(train_set_images[np.random.randint(0, train_set_images.shape[0], size=100)].reshape(100, 28, 28, 3)/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQzcCZ_hZNbH"
   },
   "source": [
    "What do you immediately notice? Indeed, these images are in color! So the generator will have to generate three output channels instead of just one. \n",
    "\n",
    "In this second-to-last part of the practical you're going to repurpose the code that you have used so far to synthesize histopathology images like the ones above. You can play around a bit with this, see what happens when you interpolate between samples, etc. Remember that there is a final 'exercise' below.\n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UCm1R35fSVlw"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8CchPs2kIVT"
   },
   "source": [
    "# Conditional image synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBALpqMLFPt2"
   },
   "source": [
    "## The BigGAN model\n",
    "The images we have synthesized so far are all quite small. Synthesis of larger images (e.g. 512 x 512 pixels) typically requires a lot of compute power and patience. Unfortunately, you don't have 100s of GPU at your disposal (I guess) to train a model like BigGAN, the state of the art in conditional image synthesis. A wild guess is that it would cost you around [USD60000](https://twitter.com/quasimondo/status/1065610256917692416) to train this model.\n",
    "\n",
    "Luckily, the authors of BigGAN have put a version of their pretrained model online and you can use it to synthesize images. Go to [this Colaboratory file](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb) and answer the following questions.\n",
    "\n",
    "**Question** What happens when you change the noise seed? Also try out different categories.\n",
    "\n",
    "**Question** What happens to your samples when you change the truncation value? More precisely, what happens to the diversity and the quality of your samples? Take a look at the [paper on arXiv](https://arxiv.org/abs/1809.11096) Sec. 3.1 to get an idea what this value does.\n",
    "\n",
    "**Question** Interpolate between image categories, inspect what these look like. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqKCNciykQ-2"
   },
   "source": [
    "## Conditional MNIST synthesis\n",
    "For all MNIST samples we already have labels (0, 1, ..., n). Try to change the MNIST synthesis code such that you can ask the generator to generate specific labels. I.e., try to train a conditional GAN. You can look for some inspiration in [this paper](https://arxiv.org/pdf/1411.1784.pdf), in particular Sec. 4.1. Remember that you already got the MNIST labels when loading the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBQvHB70RjZi"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "You can download some pre-trained generator models for the GAN training exercises from [this link](https://filesender.surf.nl/?s=download&token=bc54f2f2-8be7-4911-92da-8935a82f2a61), but of course it's much more interesting to train them yourself. Use \n",
    "\n",
    "\n",
    "```\n",
    "generator = keras.models.load_model(filename)\n",
    "```\n",
    "\n",
    "to load the model.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "t1rhzu_KRVfD",
    "4hq5i_sySZL1",
    "jmtZkf5AnW6y",
    "dEjdfhRZsUGR",
    "S8CchPs2kIVT"
   ],
   "name": "gan_practical_local.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
